{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c3f22f7e9d090e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T14:05:12.642186Z",
     "start_time": "2024-08-20T14:05:10.528369Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5202a698a87bec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T14:05:12.651824Z",
     "start_time": "2024-08-20T14:05:12.646719Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\anaconda3\\envs\\deepl5\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# include ../../3_Datapreparation\n",
    "project_dir = Path(os.getcwd()).resolve().parent.parent\n",
    "sys.path.append(str(project_dir / '3_Data_Preparation'))\n",
    "sys.path.append(str(project_dir / '4_Modelling/Patrick/Transforms'))\n",
    "from CT_Datasets import CtScanDataset, CtScanDatasetExtended\n",
    "from Transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35433953",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CtScanDataset(df_query='BodyPart == \"Stamm\"', transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ba728f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(511, 512, 512)\n",
      "58.0\n"
     ]
    }
   ],
   "source": [
    "print(dataset[10][0].shape)\n",
    "print(dataset[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90172403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint16), 58.0)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b44bcdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 225)\n",
      "tensor(73.)\n"
     ]
    }
   ],
   "source": [
    "transformed = CtScanDataset(df_query='BodyPart == \"Stamm\"', transform=cnn_3d(), return_tensor=True)\n",
    "\n",
    "print(transformed[0][0].shape)\n",
    "print(transformed[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb84eba7ecf7ee5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T15:43:34.527262Z",
     "start_time": "2024-08-13T15:43:34.519106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\anaconda3\\envs\\deepl5\\lib\\site-packages\\torchio\\transforms\\preprocessing\\intensity\\rescale.py:89: RuntimeWarning: Rescaling image \"default_image_name\" not possible because all the intensity values are the same\n",
      "  image.set_data(self.rescale(image.data, mask, image_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 225)\n",
      "tensor(73.)\n"
     ]
    }
   ],
   "source": [
    "import torchio as tio\n",
    "\n",
    "HOUNSFIELD_AIR, HOUNSFIELD_BONE = -1000, 1900\n",
    "\n",
    "transforms = tio.Compose([\n",
    "    # Convert the input to a tensor\n",
    "    v2.Lambda(lambda x: x[:, :, np.newaxis]),\n",
    "    # dimesion D x W x C x H -> C x W x H x D\n",
    "    tio.Lambda(lambda x: x.permute(2, 1, 3, 0)),\n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    tio.RescaleIntensity((HOUNSFIELD_AIR, HOUNSFIELD_BONE), (0, 1)),\n",
    "\n",
    "    # Crop or Pad the input to the target size (600, 512, 512)\n",
    "    tio.CropOrPad((512, 512, 600)),\n",
    "\n",
    "    # Scale images to 224x224\n",
    "    tio.Resize((224, 224, 225)),\n",
    "    # Normalize with mean and std\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# apply the transform to the dataset\n",
    "transformed = CtScanDataset(df_query='BodyPart == \"Stamm\"', transform=transforms, return_tensor=True)\n",
    "\n",
    "print(transformed[0][0].shape)\n",
    "print(transformed[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fcf61bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvista'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyvista\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyvista'"
     ]
    }
   ],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "scan = dataset[10][0]\n",
    "\n",
    "# Set slice thickness and pixel spacing (adjust these values based on your data)\n",
    "slice_thickness = 3.0  # Thickness in z-direction\n",
    "pixel_spacing = [1.171875, 1.171875]  # Spacing in y and x directions\n",
    "\n",
    "# Create a PyVista grid object from the numpy array\n",
    "grid = pv.ImageData()\n",
    "\n",
    "# Set the grid dimensions: shape + 1 because we want to inject our values on the cell data\n",
    "grid.dimensions = np.array(scan.shape) + 1\n",
    "\n",
    "\n",
    "# Set the grid spacing\n",
    "grid.spacing = (slice_thickness, pixel_spacing[0], pixel_spacing[1])  # Spacing in x, y, z directions\n",
    "\n",
    "# Set the grid origin to (0, 0, 0)\n",
    "grid.origin = (0, 0, 0)\n",
    "\n",
    "# Add the data values to the cell data\n",
    "grid.cell_data[\"values\"] = scan.flatten(order=\"F\")  # Flatten the array in Fortran order\n",
    "\n",
    "# Visualize the volume\n",
    "plotter = pv.Plotter()\n",
    "opacity = [0, 0, 0.1, 0.2, 0.4, 0.6, 1]  # Adjust the opacity transfer function\n",
    "plotter.add_volume(grid, scalars=\"values\", opacity=opacity, cmap=\"bone\")\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "861f89829d341c83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:05:49.118574Z",
     "start_time": "2024-08-12T15:05:49.115102Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "import torchvision.models.video as video_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "053890a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "project_dir = Path(os.getcwd()).resolve().parent.parent\n",
    "sys.path.append(str(project_dir / '4_Modelling/Patrick/medicalNet'))\n",
    "\n",
    "from setting import Options\n",
    "from model import generate_model\n",
    "from logger import log\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from scipy import ndimage\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045185a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': './data', 'img_list': './data/train.txt', 'n_seg_classes': 2, 'learning_rate': 0.001, 'num_workers': 4, 'batch_size': 1, 'phase': 'test', 'save_intervals': 10, 'n_epochs': 200, 'input_D': 56, 'input_H': 448, 'input_W': 448, 'resume_path': '', 'pretrain_path': 'pretrain/resnet_50.pth', 'new_layer_names': ['conv_seg'], 'no_cuda': True, 'gpu_id': None, 'model': 'resnet', 'model_depth': 50, 'resnet_shortcut': 'B', 'manual_seed': 1, 'ci_test': False, 'save_folder': './resnet_50', 'target_type': 'normal'}\n"
     ]
    }
   ],
   "source": [
    "# settting\n",
    "sets = Options()\n",
    "sets.target_type = \"normal\"\n",
    "sets.phase = 'test'\n",
    "print(vars(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77765f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Studium\\0004_Master_ITS\\MITS_2.Semester\\R_D\\inferring_body_weight_from_ct_scans\\4_Modelling\\Patrick\\medicalNet\\resnet.py:173: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
     ]
    }
   ],
   "source": [
    "# getting model\n",
    "sets.resume_path = sets.pretrain_path = project_dir / 'Model/3D/resnet_10.pth'\n",
    "#checkpoint = torch.load(sets.resume_path)\n",
    "net, _ = generate_model(sets)\n",
    "#net.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47ee7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResNetRegression(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_outputs=1):\n",
    "        super(ResNetRegression, self).__init__()\n",
    "        \n",
    "        # Keep all layers of the pretrained model\n",
    "        self.backbone = nn.Sequential(*list(pretrained_model.children())[:-1])\n",
    "        \n",
    "        # Add global average pooling (if not already included in your pretrained model)\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        \n",
    "        # Add the regression head (a fully connected layer)\n",
    "        self.fc = nn.Linear(2048, num_outputs)  # 2048 is the output of the last conv layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through the backbone\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Global average pooling to reduce the 3D output to a single vector\n",
    "        x = self.global_pool(x)\n",
    "        \n",
    "        # Flatten the pooled output\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Regression output\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6953b80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetRegression(\n",
      "  (backbone): Sequential(\n",
      "    (0): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2), dilation=(2, 2, 2), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(4, 4, 4), dilation=(4, 4, 4), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (global_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the new regression model\n",
    "model = ResNetRegression(net, num_outputs=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdaad5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CtScanDataset(df_query='BodyPart == \"Stamm\"', transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbdedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\anaconda3\\envs\\deepl5\\lib\\site-packages\\torchio\\transforms\\preprocessing\\intensity\\rescale.py:89: RuntimeWarning: Rescaling image \"default_image_name\" not possible because all the intensity values are the same\n",
      "  image.set_data(self.rescale(image.data, mask, image_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 225)\n",
      "torch.Size([1, 1, 224, 224, 225])\n",
      "torch.Size([1, 1, 224, 224, 225])\n",
      "tensor([[0.3663]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# get the prediction for the first sample\n",
    "sample = dataset[0][0]\n",
    "print(sample.shape)\n",
    "# make it to a tensor from the numpy array\n",
    "sample = torch.from_numpy(sample).unsqueeze(0).float()\n",
    "print(sample.shape)\n",
    "prediction = model(sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b72ee08388e4a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:05:49.257507Z",
     "start_time": "2024-08-12T15:05:49.253232Z"
    }
   },
   "outputs": [],
   "source": [
    "# train/validation split\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the trainset smaller\n",
    "train_set = torch.utils.data.Subset(train_set, range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34add5e574867d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:05:49.394868Z",
     "start_time": "2024-08-12T15:05:49.258511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "batch_size = 1\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Assuming you have your dataset ready\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca45730c591e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:38:21.029349Z",
     "start_time": "2024-08-12T15:05:49.395371Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\anaconda3\\envs\\R_D\\Lib\\site-packages\\torchio\\transforms\\preprocessing\\intensity\\rescale.py:89: RuntimeWarning: Rescaling image \"default_image_name\" not possible because all the intensity values are the same\n",
      "  image.set_data(self.rescale(image.data, mask, image_name))\n",
      "d:\\Programme\\anaconda3\\envs\\R_D\\Lib\\site-packages\\torchio\\transforms\\transform.py:168: RuntimeWarning: Output shape (224, 224, 225) != target shape (224, 224, 224). Fixing with CropOrPad\n",
      "  transformed = self.apply_transform(subject)\n",
      "d:\\Programme\\anaconda3\\envs\\R_D\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9934.2197, grad_fn=<MseLossBackward0>)\n",
      "tensor(5830.8394, grad_fn=<MseLossBackward0>)\n",
      "tensor(4830.4155, grad_fn=<MseLossBackward0>)\n",
      "tensor(990.0189, grad_fn=<MseLossBackward0>)\n",
      "tensor(4942.9980, grad_fn=<MseLossBackward0>)\n",
      "tensor(3295.8499, grad_fn=<MseLossBackward0>)\n",
      "tensor(7327.4263, grad_fn=<MseLossBackward0>)\n",
      "tensor(2153.8467, grad_fn=<MseLossBackward0>)\n",
      "tensor(3011.2346, grad_fn=<MseLossBackward0>)\n",
      "tensor(1517.7406, grad_fn=<MseLossBackward0>)\n",
      "Epoch [1/1], Train Loss: 4383.4590, Val Loss: 45567.6233\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    \n",
    "    # Training loop\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    # Compute the average training loss for this epoch\n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation loop (no gradients needed)\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "    # Compute the average validation loss for this epoch\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a50a3802258923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:38:21.152559Z",
     "start_time": "2024-08-12T15:38:21.030352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the training and validation loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a00414d513c16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:38:21.200163Z",
     "start_time": "2024-08-12T15:38:21.152559Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(resnet.state_dict(), \"resnet18CT_Rudimentary.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
